"use strict";(self.webpackChunkkb=self.webpackChunkkb||[]).push([[6734],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>h});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var p=n.createContext({}),u=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},m=function(e){var t=u(e.components);return n.createElement(p.Provider,{value:t},e.children)},s={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,l=e.originalType,p=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),c=u(a),h=i,g=c["".concat(p,".").concat(h)]||c[h]||s[h]||l;return a?n.createElement(g,r(r({ref:t},m),{},{components:a})):n.createElement(g,r({ref:t},m))}));function h(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var l=a.length,r=new Array(l);r[0]=c;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o.mdxType="string"==typeof e?e:i,r[1]=o;for(var u=2;u<l;u++)r[u]=a[u];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},7419:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>r,default:()=>s,frontMatter:()=>l,metadata:()=>o,toc:()=>u});var n=a(7462),i=(a(7294),a(3905));const l={},r="LLMs (Large Language Models)",o={unversionedId:"ml/large-language-models",id:"ml/large-language-models",title:"LLMs (Large Language Models)",description:"- LLM Worksheet - Google Sheets",source:"@site/docs/01-ml/large-language-models.md",sourceDirName:"01-ml",slug:"/ml/large-language-models",permalink:"/docs/ml/large-language-models",draft:!1,editUrl:"https://github.com/michalwols/kb/edit/master/docs/01-ml/large-language-models.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Label Noise",permalink:"/docs/ml/label-noise"},next:{title:"Long Tail Classification and Class Imbalance",permalink:"/docs/ml/long-tail"}},p={},u=[{value:"Tokenization",id:"tokenization",level:3},{value:"Chat",id:"chat",level:2},{value:"Alignment",id:"alignment",level:2},{value:"Instruction Tuning",id:"instruction-tuning",level:3},{value:"RLHF",id:"rlhf",level:3},{value:"DPO",id:"dpo",level:3},{value:"Training",id:"training",level:2},{value:"Fine Tuning",id:"fine-tuning",level:3},{value:"Inference",id:"inference",level:2},{value:"Serving",id:"serving",level:2},{value:"Quantization",id:"quantization",level:3},{value:"Tutorials",id:"tutorials",level:2},{value:"Visualization",id:"visualization",level:3},{value:"Inference Benchmarks",id:"inference-benchmarks",level:2},{value:"Evaluation",id:"evaluation",level:2},{value:"Applications",id:"applications",level:2},{value:"Text to SQL",id:"text-to-sql",level:3}],m={toc:u};function s(e){let{components:t,...a}=e;return(0,i.kt)("wrapper",(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"llms-large-language-models"},"LLMs (Large Language Models)"),(0,i.kt)("p",null,"#ml/nlp/llm"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit#gid=741531996"},"LLM Worksheet - Google Sheets"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://github.com/lm-sys/FastChat"},'GitHub - lm-sys/FastChat: The release repo for "Vicuna: An Open Chatbot Impressing GPT-4"'))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://github.com/kernelmachine/cbtm"},"GitHub - kernelmachine/cbtm: Code repository for the c-BTM paper"))),(0,i.kt)("li",{parentName:"ul"})),(0,i.kt)("h3",{id:"tokenization"},"Tokenization"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/SumanthRH/tokenization/"},"GitHub - SumanthRH/tokenization: A comprehensive deep dive into the world of tokens")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/openai/tiktoken"},"GitHub - openai/tiktoken: tiktoken is a fast BPE tokeniser for use with OpenAI's models."))),(0,i.kt)("h2",{id:"chat"},"Chat"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/imoneoi/openchat"},"GitHub - imoneoi/openchat: OpenChat: Advancing Open-source Language Models with Imperfect Data")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://blog.langchain.dev/"},"LangChain"))),(0,i.kt)("h2",{id:"alignment"},"Alignment"),(0,i.kt)("h3",{id:"instruction-tuning"},"Instruction Tuning"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/huggingface/alignment-handbook"},"GitHub - huggingface/alignment-handbook: Robust recipes for to align language models with human and AI preferences")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/allenai/open-instruct"},"GitHub - allenai/open-instruct"))),(0,i.kt)("h3",{id:"rlhf"},"RLHF"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://huggingface.co/blog/trl-peft"},"Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://huggingface.co/blog/rlhf"},"Illustrating Reinforcement Learning from Human Feedback (RLHF)"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://docs.google.com/presentation/d/1T6X8ZlwrBek14wGfKljLxikwkTBDdM88r0AZ6NiodU4/edit#slide=id.g2a01be3ce56_1_345"},"[29 Nov 2023] RLHF Lecture @ Stanford - Google Slides")))),(0,i.kt)("h3",{id:"dpo"},"DPO"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2305.18290"},"[2305.18290] Direct Preference Optimization: Your Language Model is Secretly a Reward Model"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://www.interconnects.ai/p/rlhf-progress-scaling-dpo-to-70b"},"RLHF progress: Scaling DPO to 70B, DPO vs PPO update, T\xfclu 2, Zephyr-\u03b2, meaningful evaluation, data contamination"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE?usp=sharing#scrollTo=YpdkZsMNylvp"},"Fine-tune a Mistral-7b model with DPO.ipynb"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://github.com/eric-mitchell/direct-preference-optimization"},"GitHub - eric-mitchell/direct-preference-optimization: Reference implementation for DPO (Direct Preference Optimization)"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://huggingface.co/blog/dpo-trl"},"Fine-tune Llama 2 with DPO"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://medium.com/aimonks/rlhf-and-dpo-compared-user-feedback-methods-for-llm-optimization-44f4234ae689"},"RLHF and DPO compared: user feedback methods for LLM optimization | by Automata | \ud835\udc00\ud835\udc08 \ud835\udc26\ud835\udc28\ud835\udc27\ud835\udc24\ud835\udc2c.\ud835\udc22\ud835\udc28 | Oct, 2023 | Medium")))),(0,i.kt)("h2",{id:"training"},"Training"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://rentry.org/llm-training"},"The Novice's LLM Training Guide"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2310.18313"},"[2310.18313] FP8-LM: Training FP8 Large Language Models")))),(0,i.kt)("h3",{id:"fine-tuning"},"Fine Tuning"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/OpenAccess-AI-Collective/axolotl"},"GitHub - OpenAccess-AI-Collective/axolotl: Go ahead and axolotl questions"))),(0,i.kt)("h2",{id:"inference"},"Inference"),(0,i.kt)("h2",{id:"serving"},"Serving"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://hamel.dev/notes/llm/inference/03_inference.html"},"Hamel\u2019s Blog - Optimizing latency"))),(0,i.kt)("h3",{id:"quantization"},"Quantization"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/PanQiWei/AutoGPTQ"},"GitHub - PanQiWei/AutoGPTQ: An easy-to-use LLMs quantization package with user-friendly apis, based on GPTQ algorithm.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/IST-DASLab/gptq"},'GitHub - IST-DASLab/gptq: Code for the ICLR 2023 paper "GPTQ: Accurate Post-training Quantization of Generative Pretrained Transformers".'))),(0,i.kt)("h2",{id:"tutorials"},"Tutorials"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/RahulSChand/llama2.c-for-dummies"},"GitHub - RahulSChand/llama2.c-for-dummies: Step by step explanation/tutorial of llama2.c"))),(0,i.kt)("h3",{id:"visualization"},"Visualization"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://bbycroft.net/llm"},"LLM Visualization"))),(0,i.kt)("h2",{id:"inference-benchmarks"},"Inference Benchmarks"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/ggerganov/llama.cpp/discussions/4167"},"Performance of llama.cpp on Apple Silicon \xb7 ggerganov/llama.cpp \xb7 Discussion #4167 \xb7 GitHub"))),(0,i.kt)("h2",{id:"evaluation"},"Evaluation"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://www.philschmid.de/evaluate-llm"},"Evaluate LLMs and RAG a practical example using Langchain and Hugging Face")),(0,i.kt)("h2",{id:"applications"},"Applications"),(0,i.kt)("h3",{id:"text-to-sql"},"Text to SQL"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/defog-ai/sqlcoder"},"GitHub - defog-ai/sqlcoder: SoTA LLM for converting natural language questions to SQL queries"))))}s.isMDXComponent=!0}}]);