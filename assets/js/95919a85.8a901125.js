"use strict";(self.webpackChunkkb=self.webpackChunkkb||[]).push([[3384],{3905:(e,t,r)=>{r.d(t,{Zo:()=>d,kt:()=>m});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function c(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?c(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):c(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},c=Object.keys(e);for(n=0;n<c.length;n++)r=c[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var c=Object.getOwnPropertySymbols(e);for(n=0;n<c.length;n++)r=c[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var i=n.createContext({}),s=function(e){var t=n.useContext(i),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},d=function(e){var t=s(e.components);return n.createElement(i.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,c=e.originalType,i=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=s(r),m=a,h=u["".concat(i,".").concat(m)]||u[m]||p[m]||c;return r?n.createElement(h,o(o({ref:t},d),{},{components:r})):n.createElement(h,o({ref:t},d))}));function m(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var c=r.length,o=new Array(c);o[0]=u;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l.mdxType="string"==typeof e?e:a,o[1]=l;for(var s=2;s<c;s++)o[s]=r[s];return n.createElement.apply(null,o)}return n.createElement.apply(null,r)}u.displayName="MDXCreateElement"},8918:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>i,contentTitle:()=>o,default:()=>p,frontMatter:()=>c,metadata:()=>l,toc:()=>s});var n=r(7462),a=(r(7294),r(3905));const c={},o="GPU / CUDA Programming",l={unversionedId:"dev/cuda",id:"dev/cuda",title:"GPU / CUDA Programming",description:"CUDA C++ Programming Guide",source:"@site/docs/02-dev/cuda.md",sourceDirName:"02-dev",slug:"/dev/cuda",permalink:"/docs/dev/cuda",draft:!1,editUrl:"https://github.com/michalwols/kb/edit/master/docs/02-dev/cuda.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Cloud Computing",permalink:"/docs/dev/cloud"},next:{title:"Django",permalink:"/docs/dev/django"}},i={},s=[{value:"Kernel",id:"kernel",level:3},{value:"2D Blocks",id:"2d-blocks",level:3},{value:"GPU Architecture",id:"gpu-architecture",level:2},{value:"H100 (Nvidia Hopper Architecture)",id:"h100-nvidia-hopper-architecture",level:3},{value:"H100 Thread Block Clusters",id:"h100-thread-block-clusters",level:4}],d={toc:s};function p(e){let{components:t,...c}=e;return(0,a.kt)("wrapper",(0,n.Z)({},d,c,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"gpu--cuda-programming"},"GPU / CUDA Programming"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html"},"CUDA C++ Programming Guide")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://www.elsevier.com/books/programming-massively-parallel-processors/hwu/978-0-323-91231-0"},"Programming Massively Parallel Processors (2022)")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://siboehm.com/articles/22/CUDA-MMM"},"How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://safari.ethz.ch/projects_and_seminars/fall2022/doku.php?id=heterogeneous_systems"},"Programming Heterogeneous Computing Systems with GPUs and other Accelerators (Fall 2022)")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-cpp"},"\n__global__ void kernel();  // define cuda kernel\n\ncudaMalloc((void**)&d, bytes);\ncudaMemCpy(dev, host, bytes, cudaMemcpyHostToDevice);\n\nconst unsigned int numBlocks = 8;\nconst unsigned int numThreads = 64;\n\nkernel<<<numBlocks, numThreads>>>(args...);\n\ncudaMemCpy(host, dev);\n\ncudaFree(dev);\n\n\n// #blocks and #threads\n\n\n__shared__  // shared memory\n__syncthreads();\n\n\ncudaDeviceSynchronize();\n\n")),(0,a.kt)("h3",{id:"kernel"},"Kernel"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-cpp"},"\n__global__ void my_kernel(float* x, float* y) {\n\n    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n}\n\n")),(0,a.kt)("h3",{id:"2d-blocks"},"2D Blocks"),(0,a.kt)("p",null,"Row major"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"gridDim.x and gridDim.y")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-cpp"},"row = blockIdx.y * blockDim.y + threadIdx.y\ncol = blockIdx.x * blockDim.x + threadIdx.x\n")),(0,a.kt)("h2",{id:"gpu-architecture"},"GPU Architecture"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=ynlGJ1utk4c"},"HetSys Course: Lecture 4: GPU Memory Hierarchy (Fall 2022)")),(0,a.kt)("h3",{id:"h100-nvidia-hopper-architecture"},"H100 (Nvidia Hopper Architecture)"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/"},"NVIDIA Hopper Architecture In-Depth")),(0,a.kt)("h4",{id:"h100-thread-block-clusters"},"H100 Thread Block Clusters"),(0,a.kt)("p",null,"Thread blocks in the same cluster can sync and exchange data. Makes it possible to avoid having to write intermediate results to global memory"),(0,a.kt)("p",null,(0,a.kt)("img",{src:r(6079).Z,width:"1492",height:"498"})),(0,a.kt)("p",null,"thread < thread block < thread block cluster < grid"),(0,a.kt)("p",null,"GH100: 144 cores, 60MB L2 cache"),(0,a.kt)("p",null,(0,a.kt)("img",{src:r(1494).Z,width:"2462",height:"1738"})),(0,a.kt)("p",null,(0,a.kt)("img",{src:r(3163).Z,width:"2320",height:"1400"})),(0,a.kt)("p",null,"TMA (Tensor Memory Accelerator) - reduces addressing overhead"),(0,a.kt)("p",null,"Distributed Shared Memory"),(0,a.kt)("p",null,(0,a.kt)("img",{src:r(3818).Z,width:"2464",height:"1002"})),(0,a.kt)("p",null,(0,a.kt)("img",{src:r(7348).Z,width:"2380",height:"1672"})),(0,a.kt)("p",null,(0,a.kt)("img",{src:r(9150).Z,width:"2506",height:"1512"})),(0,a.kt)("p",null,(0,a.kt)("img",{src:r(2943).Z,width:"2362",height:"1726"})),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=VxEGcEXiFj4"},"Advanced Caches")),(0,a.kt)("p",null,(0,a.kt)("img",{src:r(1434).Z,width:"2430",height:"1404"})))}p.isMDXComponent=!0},6079:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/2022-10-24-06-44-42-f6ab00d162d32fbfb515749d91175bbf.png"},1494:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/2022-10-24-06-56-24-910f10433d0015bffda90588b063a309.png"},3163:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/2022-10-24-06-58-53-22af43c639087c579f1c234ee3f3e0b6.png"},3818:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/2022-10-24-07-03-04-3de910733eb226c0340740bb6afdbcbb.png"},7348:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/2022-10-24-07-04-03-86f0e50c79d720e628e7da489dad4983.png"},9150:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/2022-10-24-07-04-48-70181797d51185e1ad238d374b686a9b.png"},2943:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/2022-10-24-07-06-58-1440fb31f517198565bdc5c8fd2ea99b.png"},1434:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/2022-10-24-07-16-54-6aa7962c5e135b21a7cf6e183415a3c8.png"}}]);