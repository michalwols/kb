"use strict";(self.webpackChunkkb=self.webpackChunkkb||[]).push([[583],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>d});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function l(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?l(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):l(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function a(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},l=Object.keys(e);for(n=0;n<l.length;n++)r=l[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)r=l[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var s=n.createContext({}),p=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,l=e.originalType,s=e.parentName,c=a(e,["components","mdxType","originalType","parentName"]),u=p(r),d=o,f=u["".concat(s,".").concat(d)]||u[d]||m[d]||l;return r?n.createElement(f,i(i({ref:t},c),{},{components:r})):n.createElement(f,i({ref:t},c))}));function d(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var l=r.length,i=new Array(l);i[0]=u;var a={};for(var s in t)hasOwnProperty.call(t,s)&&(a[s]=t[s]);a.originalType=e,a.mdxType="string"==typeof e?e:o,i[1]=a;for(var p=2;p<l;p++)i[p]=r[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}u.displayName="MDXCreateElement"},1016:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>l,metadata:()=>a,toc:()=>p});var n=r(7462),o=(r(7294),r(3905));const l={},i="Model Compression",a={unversionedId:"ml/deployment/compression",id:"ml/deployment/compression",title:"Model Compression",description:"- DeepSparse",source:"@site/docs/ml/deployment/compression.md",sourceDirName:"ml/deployment",slug:"/ml/deployment/compression",permalink:"/docs/ml/deployment/compression",draft:!1,editUrl:"https://github.com/michalwols/kb/edit/master/docs/ml/deployment/compression.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Machine Learning Compilers",permalink:"/docs/ml/deployment/compilers"},next:{title:"Mobile Inference",permalink:"/docs/ml/deployment/mobile-inference"}},s={},p=[{value:"Knowledge Distillation",id:"knowledge-distillation",level:2},{value:"Lectures",id:"lectures",level:2}],c={toc:p};function m(e){let{components:t,...r}=e;return(0,o.kt)("wrapper",(0,n.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"model-compression"},"Model Compression"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://github.com/neuralmagic/deepsparse"},"DeepSparse"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://neuralmagic.com/blog/benchmark-resnet50-with-deepsparse/?utm_campaign=Social&utm_content=217592900&utm_medium=social&utm_source=twitter&hss_channel=tw-997536616481722369"},"ResNet-50 on CPUs: Sparsifying for Better Performance")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://github.com/open-mmlab/mmrazor"},"GitHub - open-mmlab/mmrazor: OpenMMLab Model Compression Toolbox and Benchmark."))),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/TimDettmers/bitsandbytes"},"GitHub - TimDettmers/bitsandbytes: 8-bit CUDA functions for PyTorch")),(0,o.kt)("h2",{id:"knowledge-distillation"},"Knowledge Distillation"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"/docs/ml/cv/distill"},"For Knowledge Distillation see this note")),(0,o.kt)("h2",{id:"lectures"},"Lectures"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://efficientml.ai/schedule/"},"https://efficientml.ai/schedule/")))}m.isMDXComponent=!0}}]);