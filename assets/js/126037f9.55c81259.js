"use strict";(self.webpackChunkkb=self.webpackChunkkb||[]).push([[6649],{3905:(t,e,r)=>{r.d(e,{Zo:()=>u,kt:()=>s});var i=r(7294);function a(t,e,r){return e in t?Object.defineProperty(t,e,{value:r,enumerable:!0,configurable:!0,writable:!0}):t[e]=r,t}function n(t,e){var r=Object.keys(t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(t);e&&(i=i.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),r.push.apply(r,i)}return r}function o(t){for(var e=1;e<arguments.length;e++){var r=null!=arguments[e]?arguments[e]:{};e%2?n(Object(r),!0).forEach((function(e){a(t,e,r[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(r)):n(Object(r)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(r,e))}))}return t}function l(t,e){if(null==t)return{};var r,i,a=function(t,e){if(null==t)return{};var r,i,a={},n=Object.keys(t);for(i=0;i<n.length;i++)r=n[i],e.indexOf(r)>=0||(a[r]=t[r]);return a}(t,e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(t);for(i=0;i<n.length;i++)r=n[i],e.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(t,r)&&(a[r]=t[r])}return a}var p=i.createContext({}),c=function(t){var e=i.useContext(p),r=e;return t&&(r="function"==typeof t?t(e):o(o({},e),t)),r},u=function(t){var e=c(t.components);return i.createElement(p.Provider,{value:e},t.children)},m={inlineCode:"code",wrapper:function(t){var e=t.children;return i.createElement(i.Fragment,{},e)}},h=i.forwardRef((function(t,e){var r=t.components,a=t.mdxType,n=t.originalType,p=t.parentName,u=l(t,["components","mdxType","originalType","parentName"]),h=c(r),s=a,d=h["".concat(p,".").concat(s)]||h[s]||m[s]||n;return r?i.createElement(d,o(o({ref:e},u),{},{components:r})):i.createElement(d,o({ref:e},u))}));function s(t,e){var r=arguments,a=e&&e.mdxType;if("string"==typeof t||a){var n=r.length,o=new Array(n);o[0]=h;var l={};for(var p in e)hasOwnProperty.call(e,p)&&(l[p]=e[p]);l.originalType=t,l.mdxType="string"==typeof t?t:a,o[1]=l;for(var c=2;c<n;c++)o[c]=r[c];return i.createElement.apply(null,o)}return i.createElement.apply(null,r)}h.displayName="MDXCreateElement"},7933:(t,e,r)=>{r.r(e),r.d(e,{assets:()=>p,contentTitle:()=>o,default:()=>m,frontMatter:()=>n,metadata:()=>l,toc:()=>c});var i=r(7462),a=(r(7294),r(3905));const n={},o="PyTorch",l={unversionedId:"dev/pytorch",id:"dev/pytorch",title:"PyTorch",description:"Performance Optimizations",source:"@site/docs/02-dev/pytorch.md",sourceDirName:"02-dev",slug:"/dev/pytorch",permalink:"/docs/dev/pytorch",draft:!1,editUrl:"https://github.com/michalwols/kb/edit/master/docs/02-dev/pytorch.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Python",permalink:"/docs/dev/python"},next:{title:"Ray",permalink:"/docs/dev/ray"}},p={},c=[{value:"Performance Optimizations",id:"performance-optimizations",level:2},{value:"Model Initialization",id:"model-initialization",level:3},{value:"Mixed Precision",id:"mixed-precision",level:3},{value:"Quantization",id:"quantization",level:3},{value:"Data Loading",id:"data-loading",level:3},{value:"torch.compile",id:"torchcompile",level:3},{value:"JIT",id:"jit",level:3},{value:"TorchDynamo",id:"torchdynamo",level:3},{value:"TorchInductor",id:"torchinductor",level:3},{value:"AITemplate",id:"aitemplate",level:3},{value:"Distributed",id:"distributed",level:2},{value:"Debugging and Profiling",id:"debugging-and-profiling",level:2},{value:"Memory",id:"memory",level:3},{value:"Utility Libraries",id:"utility-libraries",level:2}],u={toc:c};function m(t){let{components:e,...r}=t;return(0,a.kt)("wrapper",(0,i.Z)({},u,r,{components:e,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"pytorch"},"PyTorch"),(0,a.kt)("h2",{id:"performance-optimizations"},"Performance Optimizations"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#use-onednn-graph-with-torchscript-for-inference"},"Performance Tuning Guide \u2014 PyTorch Tutorials 2.0.0+cu117 documentation")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://huggingface.co/docs/transformers/perf_train_gpu_many"},"Efficient Training on Multiple GPUs")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/LukasHedegaard/pytorch-benchmark"},"GitHub - LukasHedegaard/pytorch-benchmark: Easily benchmark PyTorch model FLOPs, latency, throughput, allocated gpu memory and energy consumption"))),(0,a.kt)("h3",{id:"model-initialization"},"Model Initialization"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"http://lernapparat.de/faster-model-init"},"Making model initialization faster"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"use context manager with ",(0,a.kt)("inlineCode",{parentName:"li"},"__torch_function__")," to skip CPU init")))),(0,a.kt)("h3",{id:"mixed-precision"},"Mixed Precision"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/TimDettmers/bitsandbytes/"},"GitHub - TimDettmers/bitsandbytes: 8-bit CUDA functions for PyTorch")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/Azure/MS-AMP"},"GitHub - Azure/MS-AMP: Microsoft Automatic Mixed Precision Library"))),(0,a.kt)("h3",{id:"quantization"},"Quantization"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/pytorch-labs/ao"},"GitHub - pytorch-labs/ao: The torchao repository contains api's and workflows for quantization and pruning gpu models."))),(0,a.kt)("h3",{id:"data-loading"},"Data Loading"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/libffcv/ffcv"},"GitHub - libffcv/ffcv: FFCV: Fast Forward Computer Vision (and other ML workloads!)")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/mosaicml/streaming"},"GitHub - mosaicml/streaming: A Data Streaming Library for Efficient Neural Network Training"))),(0,a.kt)("h3",{id:"torchcompile"},"torch.compile"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/pytorch-labs/segment-anything-fast"},"GitHub - pytorch-labs/segment-anything-fast: A batched offline inference oriented version of segment-anything")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/pytorch-labs/gpt-fast"},"GitHub - pytorch-labs/gpt-fast: Simple and efficient pytorch-native transformer text generation in <1000 LOC of python."))),(0,a.kt)("h3",{id:"jit"},"JIT"),(0,a.kt)("h3",{id:"torchdynamo"},"TorchDynamo"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/pytorch/torchdynamo"},"https://github.com/pytorch/torchdynamo")),(0,a.kt)("p",null,"ex: ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/pytorch/torchdynamo/blob/main/benchmarks/training_loss.py"},"https://github.com/pytorch/torchdynamo/blob/main/benchmarks/training_loss.py")),(0,a.kt)("h3",{id:"torchinductor"},"TorchInductor"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747"},"https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747")),(0,a.kt)("h3",{id:"aitemplate"},"AITemplate"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/facebookincubator/AITemplate"},"https://github.com/facebookincubator/AITemplate")),(0,a.kt)("h2",{id:"distributed"},"Distributed"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("a",{parentName:"p",href:"https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide/"},"https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide/"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("a",{parentName:"p",href:"https://github.com/pytorch/pippy"},"GitHub - pytorch/PiPPy: Pipeline Parallelism for PyTorch"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html"},"Getting Started with Fully Sharded Data Parallel(FSDP) \u2014 PyTorch Tutorials 2.1.1+cu121 documentation")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/abacaj/train-with-fsdp/blob/main/train.py"},"train.py")))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("a",{parentName:"p",href:"https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many"},"Efficient Training on Multiple GPUs")))),(0,a.kt)("h2",{id:"debugging-and-profiling"},"Debugging and Profiling"),(0,a.kt)("h3",{id:"memory"},"Memory"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://zdevito.github.io/2022/08/16/memory-snapshots.html"},"Debugging PyTorch memory use with snapshots")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://zdevito.github.io/2022/08/04/cuda-caching-allocator.html"},"A guide to PyTorch's CUDA Caching Allocator"))),(0,a.kt)("h2",{id:"utility-libraries"},"Utility Libraries"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/stas00/toolbox/tree/master/pytorch"},"toolbox/pytorch at master \xb7 stas00/toolbox \xb7 GitHub"))))}m.isMDXComponent=!0}}]);