"use strict";(self.webpackChunkkb=self.webpackChunkkb||[]).push([[9637],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>h});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var c=r.createContext({}),s=function(e){var t=r.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},p=function(e){var t=s(e.components);return r.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,c=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),m=s(a),h=n,f=m["".concat(c,".").concat(h)]||m[h]||u[h]||i;return a?r.createElement(f,l(l({ref:t},p),{},{components:a})):r.createElement(f,l({ref:t},p))}));function h(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,l=new Array(i);l[0]=m;var o={};for(var c in t)hasOwnProperty.call(t,c)&&(o[c]=t[c]);o.originalType=e,o.mdxType="string"==typeof e?e:n,l[1]=o;for(var s=2;s<i;s++)l[s]=a[s];return r.createElement.apply(null,l)}return r.createElement.apply(null,a)}m.displayName="MDXCreateElement"},6392:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>i,metadata:()=>o,toc:()=>s});var r=a(7462),n=(a(7294),a(3905));const i={},l="Visual Search / CBIR / Instance Recognition / Instance Retrieval / Metric Learning",o={unversionedId:"ml/visual-search",id:"ml/visual-search",title:"Visual Search / CBIR / Instance Recognition / Instance Retrieval / Metric Learning",description:"- https://github.com/willard-yuan/awesome-cbir-papers",source:"@site/docs/01-ml/visual-search.md",sourceDirName:"01-ml",slug:"/ml/visual-search",permalink:"/docs/ml/visual-search",draft:!1,editUrl:"https://github.com/michalwols/kb/edit/master/docs/01-ml/visual-search.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Vision Language Pre Training",permalink:"/docs/ml/vision-language"},next:{title:"Dev - Software Eng",permalink:"/docs/category/dev---software-eng"}},c={},s=[{value:"Datasets",id:"datasets",level:2}],p={toc:s};function u(e){let{components:t,...a}=e;return(0,n.kt)("wrapper",(0,r.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"visual-search--cbir--instance-recognition--instance-retrieval--metric-learning"},"Visual Search / CBIR / Instance Recognition / Instance Retrieval / Metric Learning"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("a",{parentName:"p",href:"https://github.com/willard-yuan/awesome-cbir-papers"},"https://github.com/willard-yuan/awesome-cbir-papers"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2308.06954"},"[2308.06954] Global Features are All You Need for Image Retrieval and Reranking"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("a",{parentName:"p",href:"https://github.com/ShihaoShao-GH/SuperGlobal"},"GitHub - ShihaoShao-GH/SuperGlobal: ICCV 2023 Paper Global Features are All You Need for Image Retrieval and Reranking Official Repository"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2308.10832"},"[2308.10832] EigenPlaces: Training Viewpoint Robust Models for Visual Place Recognition"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("a",{parentName:"p",href:"https://github.com/yash0307/RecallatK_surrogate"},"Recall@K Surrogate"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("a",{parentName:"p",href:"https://github.com/elias-ramzi/ROADMAP"},"GitHub - elias-ramzi/ROADMAP: This repository contains the official implementation of the NeurIPS\u201921 paper, ROADMAP: Robust and Decomposable Average Precision for Image Retrieval.")))),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vadimkantorov/metriclearningbench"},"GitHub - vadimkantorov/metriclearningbench: Metric learning models in PyTorch with results on CUB2011, CARS196, Stanford Online Products")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/rom1504/clip-retrieval"},"GitHub - rom1504/clip-retrieval: Easily compute clip embeddings and build a clip retrieval system with them"))),(0,n.kt)("h2",{id:"datasets"},"Datasets"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nikosips/met"},"Met Dataset")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/visipedia/inat_comp"},"GitHub - visipedia/inat_comp: iNaturalist competition details")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/01BB01/eBayChallenge"},"GitHub - 01BB01/eBayChallenge: FGVC9-CVPR2022 The second place solution for 2nd eBay eProduct Visual Search Challenge."))))}u.isMDXComponent=!0}}]);