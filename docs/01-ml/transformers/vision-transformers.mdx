
# Transformers in Vision


## Architectures

### ViT





### Swin


### DEIT

[GitHub - facebookresearch/deit: Official DeiT repository](https://github.com/facebookresearch/deit)


## Training

### Small Data

https://github.com/hananshafi/vits-for-small-scale-datasets


## Detection

### VitDet
[detectron2/projects/ViTDet at main · facebookresearch/detectron2 · GitHub](https://github.com/facebookresearch/detectron2/tree/main/projects/ViTDet#lvis)

# Links

## Code
- [GitHub - lucidrains/vit-pytorch: Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch](https://github.com/lucidrains/vit-pytorch)

## Videos
- [Transformers in Vision: From Zero to Hero (2021)](https://www.youtube.com/watch?v=J-utjBdLCTo)
- [Workshop on Attention and Transformers in Vision | CVPR 2022](https://www.youtube.com/playlist?list=PLki3HkfgNEsKa0vP-mZCfWccEFyrT93y_)
- [Beyond Convolutional Neural Networks | CVPR 2022 Tutorial](https://www.youtube.com/watch?v=QdGWCUOO6xw)



## Papers

- [Efficient Transformers: A Survey](https://arxiv.org/abs/2009.06732)
- [GitHub - Sense-X/SiT: Official implementation of “Self-slimmed Vision Transformer” (ECCV2022)](https://github.com/Sense-X/SiT)