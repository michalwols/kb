# Model Compression


- [DeepSparse](https://github.com/neuralmagic/deepsparse)
  - [ResNet-50 on CPUs: Sparsifying for Better Performance](https://neuralmagic.com/blog/benchmark-resnet50-with-deepsparse/?utm_campaign=Social&utm_content=217592900&utm_medium=social&utm_source=twitter&hss_channel=tw-997536616481722369)
- [GitHub - open-mmlab/mmrazor: OpenMMLab Model Compression Toolbox and Benchmark.](https://github.com/open-mmlab/mmrazor)




[GitHub - TimDettmers/bitsandbytes: 8-bit CUDA functions for PyTorch](https://github.com/TimDettmers/bitsandbytes)


## Knowledge Distillation

- [GitHub - Alibaba-MIIL/Solving_ImageNet: Official PyTorch implementation of  the paper: “Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results” (2022)](https://github.com/Alibaba-MIIL/Solving_ImageNet)
- [Knowledge distillation: A good teacher is patient and consistent](https://arxiv.org/abs/2106.05237)
- [GitHub - google-research/big_transfer: Official repository for the “Big Transfer (BiT): General Visual Representation Learning” paper.](https://github.com/google-research/big_transfer)